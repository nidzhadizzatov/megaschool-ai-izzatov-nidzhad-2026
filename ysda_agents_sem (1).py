# -*- coding: utf-8 -*-
"""ysda_agents_sem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/yandexdataschool/nlp_course/blob/2025/week10_agents/seminar/ysda_agents_sem.ipynb
"""

!pip install "vllm>=0.8.5" mcp ddgs smolagents markdownify

!nvidia-smi

import typing as tp
import subprocess

"""# Model setup

**Visit https://openrouter.ai/ to create an account, generate api key and search for models**
"""

# PROVIDER = 'OpenRouter' # OpenRouter or vLLM
PROVIDER = 'vLLM' # OpenRouter or vLLM

from getpass import getpass
if PROVIDER == 'vLLM':
    KEY = "EMPTY"
    HOST = "127.0.0.1"
    PORT = "8999"
    MODEL = "Qwen/Qwen3-4B-Instruct-2507"
    URL = f"http://{HOST}:{PORT}/v1"
else:
    MODEL = "x-ai/grok-4.1-fast"
    KEY = getpass("Your openrouter api key: ")
    URL = f"https://openrouter.ai/api/v1"

if PROVIDER == 'vLLM':
    vllm_server = subprocess.Popen([
        "python",
        "-m", "vllm.entrypoints.openai.api_server",
        "--model", MODEL,
        "--max_model_len", "16384",
        "--host", HOST,
        "--port", PORT,
        "--gpu_memory_utilization", "0.6",
        "--max_num_seqs", "16",
    ])
    #  python -m vllm.entrypoints.openai.api_server --model Qwen/Qwen3-4B-Instruct-2507 --max_model_len 16384 --host 127.0.0.1 --port 8999 --gpu_memory_utilization 0.6 --max_num_seqs 16 --temperature 0.9

# vllm_server.terminate() — остановить

from openai import OpenAI

client = OpenAI(
  base_url=URL,
  api_key=KEY,
)


response = client.chat.completions.create(
    model=MODEL,
    messages=[{"role": "user", "content": "Hi"}],
)

print(response.choices[0].message)

"""# How to write tools? How to use MCP?

## Tools as functions
"""

from ddgs import DDGS

def duckduckgo_search(query: str, max_results: int = 5):
    """

    """
    with DDGS() as ddgs:
        results = ddgs.text(query, max_results=max_results, )
        return list(results)

duckduckgo_search('yandex data school')

import re
import requests
from markdownify import markdownify
from requests.exceptions import RequestException
def get_webpage_content(url: str) -> str:
    try:
        response = requests.get(url)
        response.raise_for_status()

        # Convert the HTML content to Markdown
        markdown_content = markdownify(response.text).strip()
        # Remove multiple line breaks
        markdown_content = re.sub(r"\n{3,}", "\n\n", markdown_content)

        return markdown_content

    except RequestException as e:
        return f"Error fetching the webpage: {str(e)}"
    except Exception as e:
        return f"An unexpected error occurred: {str(e)}"

# Implement function to get top-5 results with full text
def websearch_full_text(query, top_k=1) -> dict[str, tp.Any]:
    # <YOUR CODE HERE>
    pass

# Test your code

"""## Run MCP Server

## Connect MCP client
"""

import asyncio
from typing import Optional
from contextlib import AsyncExitStack

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

class MCPClient:
    def __init__(self, mcps: list[str]):
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        self.mcps = mcps
        self.tools = []

    async def connect_to_server(self, server_script_path: str):
        command = "python"
        server_params = StdioServerParameters(
            command=command,
            args=[server_script_path],
            env=None
        )

        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
        self.stdio, self.write = stdio_transport
        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))
        await self.session.initialize()
        response = await self.session.list_tools()
        self.tools = response.tools

    def list_tools(self):
        print("\nConnected to server with tools:", [tool.name for tool in self.tools])
        return self.tools

    async def call_tool(self, tool_name, args):
        result = await self.session.call_tool(tool_name, args)
        return result

client = MCPClient('')
await client.connect_to_server('./ysda_tools.py')
tools = client.list_tools()

tools[0]

"""# Tool calls example"""

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_youtube_captions",
            "description": "Fetch YouTube captions for a given video ID",
            "parameters": {
                "type": "object",
                "properties": {
                    "video_id": {"type": "string"},
                    "lang": {"type": "string", "default": "en"}
                },
                "required": ["video_id"]
            }
        }
    }
]

import inspect
import typing

PYTHON_TO_JSON = {
    str: "string",
    int: "integer",
    float: "number",
    bool: "boolean",
    list: "array",
    dict: "object",
}

def create_tool_description(func):
    sig = inspect.signature(func)
    doc = inspect.getdoc(func) or ""
    params_schema = {"type": "object", "properties": {}, "required": []}

    for name, param in sig.parameters.items():
        annotation = param.annotation
        if annotation in PYTHON_TO_JSON:
            json_type = PYTHON_TO_JSON[annotation]
        else:
            json_type = "string"  # fallback

        entry = {"type": json_type}

        if param.default is not inspect.Parameter.empty:
            entry["default"] = param.default
        else:
            params_schema["required"].append(name)

        params_schema["properties"][name] = entry

    return {
        "type": "function",
        "function": {
            "name": func.__name__,
            "description": doc,
            "parameters": params_schema,
        },
    }

# Convert python function to openai tool

"""# ReAct Agent from scratch"""

instruction = """Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation, and Action can be three types:
(1) Search[query], which searches the web for the query and returns url, title and small snippet for 5 relevant pages.
(2) Visit web-page[link], which returns content of the page provided.
(3) Finish[answer], which returns the answer and finishes the task.
"""


final_prompt = "YOUR PROMPT WITH FEW SHOTS"

def llm(prompt, stop=["\n"]):
    response = client.chat.completions.create(
      model=MODEL,
      prompt=prompt,
      temperature=0,
      max_tokens=100,
      top_p=1,
      frequency_penalty=0.0,
      presence_penalty=0.0,
      stop=stop
    )
    return response["choices"][0]["text"]

def execute_action(action: str) -> str:
    pass


def call_react(question, prompt=final_prompt, to_print=True):
    prompt += question + "\n"
    n_calls, n_badcalls = 0, 0
    for i in range(1, 8):
        n_calls += 1
        # Generate thought
        thought_action = <YOUR CODE HERE>
        try:
            # Extract generated action
            thought, action = thought_action.strip().split(f"\nAction {i}: ")
        except Exception as e:
            # Error handling
        # Execute action
        ... = execute_action()
        # Create observation
        obs = obs.replace('\\n', '')
        step_str = f"Thought {i}: {thought}\nAction {i}: {action}\nObservation {i}: {obs}\n"
        # Add observation to history
    return r, info



"""# Multi-agent systems with smolagents"""

from smolagents import tool


@tool
def visit_webpage(link: str) -> str:
  """
  Visit web-page[link], which returns content of the page provided.
  Args:
    link: link to the webpage
  Returns:
    content of the webpage
  """
  return get_webpage_content(link)

from smolagents import (
    CodeAgent,
    OpenAIModel,
    ToolCallingAgent,
    WebSearchTool,
)


model = OpenAIModel(
    model_id=MODEL,
    api_base=URL,
    api_key=KEY,
)


web_agent = CodeAgent(
    tools=[WebSearchTool(), visit_webpage],
    model=model,
    max_steps=5,
    name="web_search_agent",
    description="Runs web searches for you.",
)

!nvidia-smi

manager_agent = CodeAgent(
    tools=[],
    model=model,
    managed_agents=[web_agent],
)

answer = manager_agent.run(
    "How does ReAct agent works? What metrics were reported by authors?"
)

answer

from IPython.display import display, Markdown, Latex
display(Markdown(answer))

